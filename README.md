
```markdown
# ğŸš€ RAG-based NLP â†’ SQL Query Generator  
Convert **natural language questions** into **accurate SQL queries** using a **Retrieval-Augmented Generation (RAG)** pipeline powered by FastAPI, Streamlit, FAISS Vector Store, and Ollama LLM.

---

## ğŸ¥ Demo Videos

### ğŸ”¹ FastAPI Swagger Demo  
![FastAPI Demo](demo_1.gif)

### ğŸ”¹ Streamlit UI Demo  
![Streamlit Demo](output_videos/streamm.gif)

---

## ğŸ“Œ Overview

This project converts **human natural language** into **SQL queries** using an intelligent RAG architecture.  
The system understands database schema, retrieves relevant table/column information using embeddings, and generates accurate SQL using an LLM.

### âœ… Features
- ğŸ“„ Schema extraction from MySQL  
- ğŸ§  Semantic search using FAISS  
- ğŸ¤– SQL generation using Ollama LLM  
- ğŸ”Œ REST API using FastAPI  
- ğŸ–¥ï¸ Interactive UI using Streamlit  
- âš¡ End-to-end NLP â†’ SQL pipeline  

---

## ğŸ—ï¸ Architecture

```

User Query â†’ Embeddings â†’ FAISS Vector Store â†’ Retrieved Schema â†’ LLM Prompt â†’ SQL Query

```

### ğŸ§© Components
- **Schema Extractor** â†’ Reads DB schema + sample rows  
- **Embedder** â†’ Converts schema to embeddings (MiniLM)  
- **Vector Database (FAISS)** â†’ Stores embeddings  
- **Retriever** â†’ Finds top relevant columns/tables  
- **Generator** â†’ LLaMA 3 via Ollama produces SQL  
- **API** â†’ FastAPI backend  
- **UI** â†’ Streamlit interface  

---

## ğŸ“‚ Project Structure

```

â”œâ”€â”€ app.py                # FastAPI backend
â”œâ”€â”€ streamlit_app.py      # Frontend UI
â”œâ”€â”€ schema_extractor.py   # DB schema ingestion
â”œâ”€â”€ embedder.py           # Embeddings + FAISS
â”œâ”€â”€ sql_generator.py      # LLM prompt + SQL generation
â”œâ”€â”€ vector_store.faiss    # Vector store file
â”œâ”€â”€ .env                  # Environment variables
â””â”€â”€ README.md             # Documentation

````

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/nlp-to-sql.git
cd nlp-to-sql
````

### 2ï¸âƒ£ Create virtual environment

```bash
python -m venv nlp_env
source nlp_env/Scripts/activate   # Windows
# or
source nlp_env/bin/activate       # Linux / macOS
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ” Environment Variables

Create a `.env` file:

```
DATABASE_URL=mysql://user:password@localhost:3306/yourdb
OLLAMA_BASE_URL=http://localhost:11434
MODEL_NAME=llama3
```

---

## ğŸ§© Step 1: Ingest Schema & Build Vector Store

Run FastAPI backend:

```bash
uvicorn app:app --reload
```

Open:
â¡ï¸ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

Then click:

```
POST /ingest_schema
```

This will:

* Extract database schema
* Generate embeddings
* Build FAISS vector store

Your vector DB will be saved as:

```
vector_store.faiss
```

---

## ğŸ¯ Step 2: Start Streamlit UI

```bash
streamlit run streamlit_app.py
```

Now you can ask natural language questions like:

* *"Show all employees earning more than 50,000"*
* *"Get department names and total employees"*
* *"List orders placed in the last 7 days"*

---

## ğŸ§  LLM Used

This project uses **Ollama LLaMA 3** by default.

Start Ollama:

```bash
ollama run llama3
```

Change model in `.env`:

```
MODEL_NAME=llama3
```

---

## ğŸ“ Example Query

**Input:**

```
Show total salary grouped by department.
```

**Output SQL:**

```sql
SELECT department, SUM(salary)
FROM employees
GROUP BY department;
```

---

## ğŸ”® Future Improvements

* Schema relationship visualization
* Multi-table join reasoning
* Execute SQL directly from UI
* Support PostgreSQL, MongoDB
* Authentication & user history tracking

---

## ğŸ“œ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

**Mohd Zakir**

If you need:

* A project logo
* Architecture diagram
* Deployment (Docker, Railway, Render, HuggingFace Spaces)

Just let me know!

```
